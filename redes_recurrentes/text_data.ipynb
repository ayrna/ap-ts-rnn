{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/ayrna/ap2122/blob/main/redes_recurrentes/text_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMucfLUS1yhH"
   },
   "source": [
    "## ¿Qué es esto?\n",
    "\n",
    "Este cuaderno de Jupyter contiene código Python para construir una red recurrente LSTM  que proporciona alrededor de un 87-88% de precisión en el dataset *IMDB Movie Review Sentiment Analysis Dataset*. \n",
    "\n",
    "Para más información podéis consultar este [enlace](https://www.bouvet.no/bouvet-deler/explaining-recurrent-neural-networks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFUKGe4x3ala"
   },
   "source": [
    "## Pensado para Google Collaboratory\n",
    "\n",
    "El código está preparado para funcionar en Google Collab. Si queréis ejecutarlo de forma local, tendréis que configurar todos los elementos (Cuda, Tensorflow...).\n",
    "\n",
    "En Google Collab, para conseguir que la red se entrene más rápido deberíamos usar la GPU. En el menú **Entorno de ejecución** elige **Cambiar tipo de entorno de ejecución** y selecciona \"GPU\".\n",
    "\n",
    "No olvides hacer los cambios efectivos pulsando sobre **Reiniciar entorno de ejecución**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WP1VrbVp3sVu"
   },
   "source": [
    "## Preparándolo todo\n",
    "\n",
    "Al ejecutar este código, puede ser que recibas un *warning* pidiéndote que reinicies el *Entorno de ejecución*. Puedes ignorarlo o reiniciarlo con \"Entorno de ejecución -> Reiniciar entorno de ejecución\" si encuentras algún tipo de problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2e3txwbh3q76",
    "outputId": "02d1368c-9f38-45a5-a5a7-d0381364b2d8"
   },
   "outputs": [],
   "source": [
    "# Todos los import necesarios\n",
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from numpy import array\n",
    "\n",
    "# Suprimir los warning de tensorflow\n",
    "import logging\n",
    "logging.getLogger('tensorflow').disabled = True\n",
    "\n",
    "# Obtener los datos de \"IMDB Movie Review\", limitando las revisiones\n",
    "# a las 10000 palabras más comunes\n",
    "vocab_size = 10000\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=vocab_size)\n",
    "\n",
    "# Maping de las etiquetas\n",
    "class_names = [\"Negative\", \"Positive\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hdyHL8FF0JJy"
   },
   "source": [
    "## Crear un mapeo que nos permita convertir el dataset IMDB a revisiones que podamos leer\n",
    "\n",
    "Las revisiones en el dataset IMDB están codificadas como una secuencia de enteros. Afortunadamente, el dataset también contiene un índice que nos permite volver a una representación tipo texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E05AweFu0Imt",
    "outputId": "f677439b-e0c4-442e-86ad-6706eb049e7f"
   },
   "outputs": [],
   "source": [
    "# Obtener el índice de palabras del dataset\n",
    "word_index = tf.keras.datasets.imdb.get_word_index()\n",
    "\n",
    "# Asegurarnos de que las palabras \"especiales\" pueden leerse correctamente \n",
    "word_index = {k:(v+3) for k,v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNKNOWN>\"] = 2\n",
    "word_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "# Buscar las palabras en el índice y hacer una función que decodifique cada review\n",
    "# Si la palabra no está devolverá '?'\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fFXK-g6G81sC"
   },
   "source": [
    "## Echemos un vistazo a los datos\n",
    "\n",
    "Ahora vamos a ver más de cerca los datos. ¿Cuántas palabras contienen nuestras reviews?\n",
    "\n",
    "¿Qué aspecto tiene una review codificada y decodificada?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yD1qHVBn81Y_",
    "outputId": "12f6d767-8147-4ba4-e87e-44afd0a4865c"
   },
   "outputs": [],
   "source": [
    "# Concatenar los datasets de entrenamiento y de test\n",
    "allreviews = np.concatenate((x_train, x_test), axis=0)\n",
    "\n",
    "# Longitud de las revisiones a largo de los dos conjuntos\n",
    "result = [len(x) for x in allreviews]\n",
    "print(\"Máxima longitud de una revisión: {}\".format(np.max(result)))\n",
    "print(\"Mínima longitud de una revisión: {}\".format(np.min(result)))\n",
    "print(\"Longitud media de las revisiones: {}\".format(np.mean(result)))\n",
    "\n",
    "# Imprimir una revisión concreta y su etiqueta.\n",
    "# Reemplaza el número si quieres ver otra.\n",
    "review_to_print=60\n",
    "print(\"\")\n",
    "print(\"Revisión en modo máquina (codificada)\")\n",
    "print(\"  Código de la revisión: \" + str(x_train[review_to_print]))\n",
    "print(\"  Sentimiento: \" + str(y_train[review_to_print]))\n",
    "print(\"\")\n",
    "print(\"Revisión en modo texto\")\n",
    "print(\"  Texto de la revisión: \" + decode_review(x_train[review_to_print]))\n",
    "print(\"  Sentimiento: \" + class_names[y_train[review_to_print]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mF-Votm66zD5"
   },
   "source": [
    "## Pre-procesando los datos\n",
    "\n",
    "Tenemos que asegurarnos de que nuestras revisiones tienen siempre la misma\n",
    "longitud, ya que se necesita para establecer los parámetros de la LSTM.\n",
    "\n",
    "Para algunas revisiones tendremos que truncar algunas palabras, mientras que para otras habrá que establecer palabras de relleno (`padding`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uNtJTLJA6gaT",
    "outputId": "a0b50c8c-306d-4dfa-c708-7acf5f49af53"
   },
   "outputs": [],
   "source": [
    "# Longitud a la que vamos a dejar la ventana\n",
    "review_length = 500\n",
    "\n",
    "# Truncar o rellenar los conjuntos\n",
    "x_train = sequence.pad_sequences(x_train, maxlen = review_length)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen = review_length)\n",
    "\n",
    "# Comprobamos el tamaño de los conjuntos. Revisaremos los datos de entrenamiento\n",
    "# y de test, comprobando que las 25000 revisiones tienen 500 enteros.\n",
    "# Las etiquetas de clase deberían ser 25000, con valores de 0 o 1\n",
    "print(\"Shape de los datos de entrenamiento: \" + str(x_train.shape))\n",
    "print(\"Shape de la etiqueta de entrenamiento \" + str(y_train.shape))\n",
    "print(\"Shape de los datos de test: \" + str(x_test.shape))\n",
    "print(\"Shape de la etiqueta de test: \" + str(y_test.shape))\n",
    "\n",
    "# Note padding is added to start of review, not the end\n",
    "print(\"\")\n",
    "print(\"Texto de la revisión (post padding): \" + decode_review(x_train[60]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BfOdV_VCCFee"
   },
   "source": [
    "## Crear y construir una red LSTM recurrente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8nmO8M4aCKwT",
    "outputId": "d8ae5d7b-5d36-48a4-f8b3-9d9864134fe0"
   },
   "outputs": [],
   "source": [
    "# Empezamos definiendo una pila vacía. Usaremos esta pila para ir construyendo\n",
    "# la red, capa por capa\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# La capa de tipo Embedding proporciona un mapeo (también llamado Word Embedding)\n",
    "# para todas las palabras de nuestro conjunto de entrenamiento. En este embedding,\n",
    "# las palabras que están cerca unas de otras comparten información de contexto \n",
    "# y/o de significado. Esta transformación es aprendida durante el entrenamiento\n",
    "model.add(\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim = vocab_size, # Tamaño del vocabulario\n",
    "        output_dim = 32, # Dimensionalidad del embedding\n",
    "        input_length = review_length # Longitud de las secuencias de entrada\n",
    "    )\n",
    ")\n",
    "\n",
    "# Las capas de tipo Dropout combaten el sobre aprendizaje y fuerzan a que el \n",
    "# modelo aprenda múltiples representaciones de los mismos datos, ya que pone a \n",
    "# cero de forma aleatoria algunas de las neuronas durante la fase de \n",
    "# entrenamiento\n",
    "model.add(\n",
    "    tf.keras.layers.Dropout(\n",
    "        rate=0.25 # Poner a cero aleatoriamente un 25% de las neuronas\n",
    "    )\n",
    ")\n",
    "\n",
    "# Aquí es donde viene realmente la capa LSTM. Esta capa va a mirar cada \n",
    "# secuencia de palabras de la revisión junto con sus embeddings y utilizará \n",
    "# ambos elementos para determinar el sentimiento de la revisión\n",
    "model.add(\n",
    "    tf.keras.layers.LSTM(\n",
    "        units=32 # La capa va a tener 32 neuronas de tipo LSTM\n",
    "    )\n",
    ")\n",
    "\n",
    "# Añadir una segunda capa Dropout con el mismo objetivo que la primera\n",
    "model.add(\n",
    "    tf.keras.layers.Dropout(\n",
    "        rate=0.25 # Poner a cero aleatoriamente un 25% de las neuronas\n",
    "    )\n",
    ")\n",
    "\n",
    "# Todas las neuronas LSTM se conectan a un solo nodo en la capa densa. La \n",
    "# función sigmoide determina la salida de este nodo, con un valor entre 0 y 1.\n",
    "# Cuanto más cercano sea a 1, más positiva es la revisión\n",
    "model.add(\n",
    "    tf.keras.layers.Dense(\n",
    "        units=1, # Una única salida\n",
    "        activation='sigmoid' # Función de activación sigmoide\n",
    "    )\n",
    ")\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.binary_crossentropy, # Entropía cruzada\n",
    "    optimizer=tf.keras.optimizers.Adam(), # Optimizador Adam\n",
    "    metrics=['accuracy']) # Métrica de los informes\n",
    "\n",
    "# Mostrar un resumen de la estructura del modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Xx1Q2I8WNI9"
   },
   "source": [
    "## Visualizar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 644
    },
    "id": "cz0Erj2WU3Vh",
    "outputId": "c0b17ba2-4557-4e7d-ad46-e265b8bac2a0"
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5KdfAoHsGwzo"
   },
   "source": [
    "## Entrenar la LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rEN1vV4nG1V3",
    "outputId": "5b49e568-5f03-4779-9571-307ab67538b1"
   },
   "outputs": [],
   "source": [
    "# Entrenar la LSTM en los datos de entrenamiento\n",
    "history = model.fit(\n",
    "\n",
    "    # Datos de entrenamiento : características (revisiones) y clases (positivas o negativas)\n",
    "    x_train, y_train,\n",
    "                    \n",
    "    # Número de ejemplos a examinar antes de actualizar los pesos en el \n",
    "    # backpropagation. Cuanto más grande sea el tamaño de batch, más memoria\n",
    "    # necesitaremos\n",
    "    batch_size=256, \n",
    "\n",
    "    # Una época hace tantos batches como sea necesario para agotar el conjunto\n",
    "    # de entrenamiento\n",
    "    epochs=3, \n",
    "    \n",
    "    # Esta fracción de los datos será usada como conjunto de validación, con \n",
    "    # vistas a detener el algoritmo si se está produciendo sobre aprendizaje\n",
    "    validation_split=0.2,\n",
    "    \n",
    "    verbose=1\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rpCS2-jFH1KY"
   },
   "source": [
    "## Evaluar el modelo con los datos de test y ver el resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nPnfxwbnITqV",
    "outputId": "33cab1c7-7d96-49f8-e3e3-13216018d026"
   },
   "outputs": [],
   "source": [
    "# Obtener las predicciones para los datos de test\n",
    "from sklearn.metrics import classification_report\n",
    "predicted_probabilities = model.predict(x_test)\n",
    "predicted_classes = predicted_probabilities  > 0.5\n",
    "print(classification_report(y_test, predicted_classes, target_names=class_names))\n",
    "tf.math.confusion_matrix(y_test, predicted_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CkfHCIVHrJni"
   },
   "source": [
    "## Ver algunas predicciones incorrectas\n",
    "\n",
    "Vamos a echar un vistazo a algunas de las revisiones incorrectamente clasificadas. Eliminaremos el `padding`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bwKLBwBbp7zg",
    "outputId": "e90fb382-db47-4511-a9d1-8383c6f14c74"
   },
   "outputs": [],
   "source": [
    "predicted_classes_reshaped = np.reshape(predicted_classes, 25000)\n",
    "\n",
    "incorrect = np.nonzero(predicted_classes_reshaped!=y_test)[0]\n",
    "\n",
    "# Nos vamos a centrar en las 20 primeras revisiones incorrectas\n",
    "for j, incorrect in enumerate(incorrect[0:20]):\n",
    "    \n",
    "    predicted = class_names[predicted_classes_reshaped[incorrect].astype(int)]\n",
    "    actual = class_names[y_test[incorrect]]\n",
    "    human_readable_review = decode_review(x_test[incorrect])\n",
    "    \n",
    "    print(\"Revisión de test incorrectamente clasificada [\"+ str(j+1) +\"]\") \n",
    "    print(\"Revisión de test #\" + str(incorrect)  + \": Predicho [\"+ predicted + \"] Objetivo [\"+ actual + \"]\")\n",
    "    print(\"Texto de la revisión: \" + human_readable_review.replace(\"<PAD> \", \"\"))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OlAfxIoTrtYa"
   },
   "source": [
    "## Prueba tu propio texto como conjunto de test\n",
    "\n",
    "Esta es una forma divertida de comprobar los límites del modelo que hemos entrenado. Debes teclear todo en minúscula y no usar signos de puntuación.\n",
    "\n",
    "Podrás comprobar la predicción del modelo, un valor entre 0 y 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UEKEB0DpD_8P",
    "outputId": "2d85d0d5-8343-4b05-e78c-03cbeb9729ca"
   },
   "outputs": [],
   "source": [
    "# Escribe tu propia revisión (EN INGLÉS)\n",
    "#review = \"this was a terrible film with too much sex and violence i walked out halfway through\"\n",
    "review = \"this is the best film i have ever seen it is great and fantastic and i loved it\"\n",
    "#review = \"this was an awful film that i will never see again\"\n",
    "#review = \"absolutely wonderful movie i am sure i will repeat it really worth the money i am delighted with the actors and i think it is epic the best movie from this director it is really fantastic and super\"\n",
    "\n",
    "# Codificamos la revisión (reemplazamos las palabras por los enteros)\n",
    "tmp = []\n",
    "for word in review.split(\" \"):\n",
    "    tmp.append(word_index[word])\n",
    "\n",
    "# Nos aseguramos que la longitud de secuencia es 500\n",
    "tmp_padded = sequence.pad_sequences([tmp], maxlen=review_length) \n",
    "\n",
    "# Introducimos la revisión ya procesada en el modelo\n",
    "rawprediction = model.predict(array([tmp_padded][0]))[0][0]\n",
    "prediction = int(round(rawprediction))\n",
    "\n",
    "# Probamos el modelo y vemos los resultados\n",
    "print(\"Revisión: \" + review)\n",
    "print(\"Predicción numérica: \" + str(rawprediction))\n",
    "print(\"Clase predicha: \" + class_names[prediction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zHROnRa9bRQS"
   },
   "source": [
    "## Redes GRU\n",
    "\n",
    "Ahora vamos a repetir el entrenamiento pero con las redes GRU. Recuerda que las redes Gated Recurrent Unit (GRU) implementan una simplificación de la neurona LSTM basada en reducir el número de puertas, parámetros y estaddos de la misma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SAp18yLnZKaL",
    "outputId": "30708700-0a86-4266-e1e7-0f48b78e619d"
   },
   "outputs": [],
   "source": [
    "# Pila vacía\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "# Embedding\n",
    "model.add(\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim = vocab_size, # Tamaño del vocabulario\n",
    "        output_dim = 32, # Dimensionalidad del embedding\n",
    "        input_length = review_length # Longitud de las secuencias de entrada\n",
    "    )\n",
    ")\n",
    "\n",
    "# Primer Dropout\n",
    "model.add(\n",
    "    tf.keras.layers.Dropout(\n",
    "        rate=0.25 # Poner a cero aleatoriamente un 25% de las neuronas\n",
    "    )\n",
    ")\n",
    "\n",
    "# Capa GRU\n",
    "model.add(\n",
    "    tf.keras.layers.GRU(\n",
    "        units=32 # La capa va a tener 32 neuronas de tipo LSTM\n",
    "    )\n",
    ")\n",
    "\n",
    "# Segundo Dropout\n",
    "model.add(\n",
    "    tf.keras.layers.Dropout(\n",
    "        rate=0.25 # Poner a cero aleatoriamente un 25% de las neuronas\n",
    "    )\n",
    ")\n",
    "\n",
    "# Capa densa final\n",
    "model.add(\n",
    "    tf.keras.layers.Dense(\n",
    "        units=1, # Una única salida\n",
    "        activation='sigmoid' # Función de activación sigmoide\n",
    "    )\n",
    ")\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.binary_crossentropy, # Entropía cruzada\n",
    "    optimizer=tf.keras.optimizers.Adam(), # Optimizador Adam\n",
    "    metrics=['accuracy']) # Métrica de los informes\n",
    "\n",
    "# Mostrar un resumen de la estructura del modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 644
    },
    "id": "07ahFqW9br-2",
    "outputId": "bd9322e5-3c16-4c33-e319-30bb1de7d103"
   },
   "outputs": [],
   "source": [
    "# Representar el modelo\n",
    "tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8LelP9R1bwzW",
    "outputId": "4545b78e-612f-417e-f22f-a0bc09d1a474"
   },
   "outputs": [],
   "source": [
    "# Entrenar la GRU en los datos\n",
    "history = model.fit(\n",
    "\n",
    "    # Datos de entrenamiento\n",
    "    x_train, y_train,\n",
    "                    \n",
    "    # Tamaño de batch\n",
    "    batch_size=256, \n",
    "\n",
    "    # Número de épocas\n",
    "    epochs=3, \n",
    "    \n",
    "    # Porcentaje de validación\n",
    "    validation_split=0.2,\n",
    "    \n",
    "    verbose=1\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UyQgjOyub02c",
    "outputId": "ede645c7-54c7-4597-f23a-e69d57509cee"
   },
   "outputs": [],
   "source": [
    "# Obtener las predicciones para los datos de test\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "predicted_probabilities = model.predict(x_test)\n",
    "predicted_classes = predicted_probabilities  > 0.5\n",
    "print(classification_report(y_test, predicted_classes, target_names=class_names))\n",
    "tf.math.confusion_matrix(y_test, predicted_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NzMNJuepgGJo"
   },
   "source": [
    "## Referencia\n",
    "\n",
    "Este material ha sido elaborado a partir del [cuaderno](https://github.com/markwest1972/LSTM-Example-Google-Colaboratory) de Mark West"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q-v812F9dlKi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "text_data.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
