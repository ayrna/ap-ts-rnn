{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ayrna/ap2122/blob/main/redes_recurrentes/time_series_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "maINzqlPD1U7"
   },
   "source": [
    "# Utilizar Keras para construir y entrenar redes LSTM con series temporales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vd9vw6EID1VB"
   },
   "source": [
    "En este cuaderno, vamos a usar keras para construir una red LSTM que resuelva un problema de predicción en series temporales.\n",
    "\n",
    "El problema que vamos a estudiar es el de predicción de pasajeros de líneas aéreas internacionales. Para este problema se nos da un año y un mes y tenemos que predecir el número de pasajeros de líneas aéreas internacionales en unidades de 1.000. En otras palabras, tenemos que responder a la pregunta: \"Dado el número de pasajeros (en unidades de miles) de este mes, ¿cuál será el número de pasajeros del próximo mes?\". \n",
    "\n",
    "Los datos van de enero de 1949 a diciembre de 1960 con 144 observaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YfSd4kU9D1VF"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KMKH3XSCD1VK"
   },
   "source": [
    "El siguiente paso es cargar nuestro conjunto de datos de entrenamiento como un `DataFrame` de Pandas. A continuación, podemos extraer la matriz `numpy` del `DataFrame` y convertir los valores enteros en valores de punto flotante, que son más adecuados para el modelado con una red neuronal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "KU1lHLL4D1VM",
    "outputId": "220cbcdc-346f-4de6-90b1-68e51d65f5e3"
   },
   "outputs": [],
   "source": [
    "# Cargar el conjunto de datos usando pandas\n",
    "try:\n",
    "    url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv\"\n",
    "    df = pd.read_csv(url)\n",
    "except:\n",
    "    df = pd.read_csv(\"./data/airline-passengers.csv\")\n",
    "\n",
    "# Dar el formato correcto a la fecha y usarlo como índice\n",
    "df.Month = pd.to_datetime(df.Month)\n",
    "df.set_index('Month', inplace=True)\n",
    "\n",
    "# Mostrar los primeros datos\n",
    "print(df.head())\n",
    "\n",
    "# Usar matplotlib para mostrar la serie\n",
    "df.plot()\n",
    "plt.title(\"Número de pasajeros desde 1949-01 a 1960-12\")\n",
    "plt.ylabel(\"Número de pasajeros\")\n",
    "plt.show()\n",
    "\n",
    "# Fijar la semilla para reproducibilidad \n",
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8NprbQq4D1VU"
   },
   "source": [
    "Las redes LSTM pueden ser sensibles a la escala de los datos de entrada. Puede ser buena idea rescalar los datos en el rango [0,1]. Para ello, vamos a usar `MinMaxScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aMlLbw22D1VX"
   },
   "outputs": [],
   "source": [
    "passengers = df['Passengers']\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(passengers.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0uQCuDeD1Vb"
   },
   "source": [
    "Después de modelar nuestros datos y estimar su rendimiento en el conjunto de datos de entrenamiento, tenemos que hacernos una idea de su comportamiento con datos no vistos. Con los datos de series temporales, la secuencia de valores es importante. Un método sencillo que podemos utilizar es dividir el conjunto de datos ordenados en conjuntos de datos de entrenamiento y otro de test. El código siguiente calcula el índice del punto de división y separa los datos en conjuntos de datos de entrenamiento con el 67% de las observaciones que podemos utilizar para entrenar nuestro modelo, dejando el 33% restante para probar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ZpBEIAvD1Vd"
   },
   "outputs": [],
   "source": [
    "train_size = int(len(dataset) * 0.67)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HlOgFbeiD1Vm"
   },
   "source": [
    "Ahora vamos a definir una función que va a generar los datos para el entrenamiento de la LSTM.\n",
    "\n",
    "La función toma dos argumentos: el conjunto de datos, que es un array de NumPy que queremos convertir en un conjunto de datos, y el look_back, que es el número de pasos de tiempo anteriores que se utilizarán como variables de entrada para predecir el siguiente período de tiempo - en este caso, por defecto, 1.\n",
    "\n",
    "Este valor predeterminado creará un conjunto de datos donde X es el número de pasajeros en un momento dado (t) e Y es el número de pasajeros en el siguiente momento (t + 1).\n",
    "\n",
    "De esta forma, estamos siguiendo la estrategia `one-to-one`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "epJhKfjZD1Vo"
   },
   "outputs": [],
   "source": [
    "# Convertir un array en un conjunto de datos\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ht2QEtHED1Vt"
   },
   "source": [
    "Ahora podemos utilizar esta función para preparar los conjuntos de datos de entrenamiento y test para el modelado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X2IPlM61D1Vv"
   },
   "outputs": [],
   "source": [
    "look_back = 1\n",
    "# Preparar el conjunto de train\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "\n",
    "# Preparar el conjunto de test\n",
    "testX, testY = create_dataset(test, look_back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YEY2veSr-HMl"
   },
   "source": [
    "Podríamos haber hecho esto de forma más fácil usando el método `shift()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54O9X3KtD1V0"
   },
   "source": [
    "La red LSTM espera que los datos de entrada (X) tenga una estructura 3D de la siguiente forma: `[samples, time steps, features]`. Los `samples` son el número de instantes (filas) que vamos a usar para entrenar. En `time_steps` tendremos tantos como entradas reciba a la vez la red por cada instante de tiempo. En `features` vamos a tener las distintas variables que pudiera considerar la red.\n",
    "\n",
    "En nuestro caso, el array es de `[samples, features]`, nos falta una dimensión. Además, `time_steps=1` (`one-to-one`) y `features=1` (univariante). Pero tenemos que convertir la X a 3D. Lo haremos usando `reshape()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MoyP9mamD1V1"
   },
   "outputs": [],
   "source": [
    "# Reshape para tener [samples, time steps, features]\n",
    "trainX = trainX.reshape(trainX.shape[0],1,trainX.shape[1])\n",
    "testX = testX.reshape(testX.shape[0],1,testX.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7WkO51TnD1V3"
   },
   "source": [
    "Ahora ya podemos diseñar nuestra red LSTM para el problema de predicción.\n",
    "\n",
    "Vamos a tener una capa visible con 1 entrada, una capa oculta con 4 bloques LSTM y una capa de salida que realizará una predicción. La función de activación sigmoide se va a usar para los bloques LSTM.\n",
    "\n",
    "La opción `stateful=True` es importante. Hace que la memoria de la LSTM no se resetee después de cada batch. Obliga a especificar el `batch_size`, ya que así sabremos la memoria máxima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "60sMcBIqD1V5"
   },
   "outputs": [],
   "source": [
    "# Tamaño de batch\n",
    "batch_size=1\n",
    "\n",
    "# Crear un modelo secuencial\n",
    "model = Sequential()\n",
    "\n",
    "# Crear una capa LSTM\n",
    "model.add(LSTM(10, batch_input_shape=(batch_size, look_back, 1), stateful=True))\n",
    "\n",
    "# Crear una capa densa\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iq4BkeO2D1V9"
   },
   "source": [
    "Ahora compilamos y entrenamos durante 100 épocas con tamaño de batch 1.\n",
    "\n",
    "Para forzar a que el estado se resetee una vez hayamos pasado por toda la serie temporal, vamos a incluir un bucle para el número de épocas, en lugar de usar la forma habitual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FafYD1PxD1V-",
    "outputId": "79766c41-31da-4198-be30-495f4b0a0bba"
   },
   "outputs": [],
   "source": [
    "# Compilar el modelo\n",
    "model.compile(optimizer=\"adam\", loss='mean_squared_error')\n",
    "\n",
    "# Entrenamiento habitual (no resetearía el estado)\n",
    "# model.fit(trainX, trainY, epochs=30, batch_size=1)\n",
    "\n",
    "# Entrenar el modelo con reseteo explícito\n",
    "for i in range(100):\n",
    "  print('Época %d'%(i))\n",
    "  model.fit(trainX, trainY, epochs=1, batch_size=batch_size, verbose=2, shuffle=False)\n",
    "  model.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26p_v-mjD1WB"
   },
   "source": [
    "Una vez ajustado el modelo, podemos estimar su rendimiento en los conjuntos de datos de entrenamiento y de test. Esto nos dará un punto de comparación para los nuevos modelos.\n",
    "\n",
    "Hay que tener en cuenta que invertimos las predicciones antes de calcular las puntuaciones de error para asegurarnos de que el rendimiento se presenta en las mismas unidades que los datos originales (miles de pasajeros al mes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J1gwbMRJD1WD",
    "outputId": "6140fb15-928c-4ad6-c7c9-9012c3bfff48"
   },
   "outputs": [],
   "source": [
    "# Realizar las predicciones\n",
    "trainPredict = model.predict(trainX,batch_size=batch_size)\n",
    "testPredict = model.predict(testX,batch_size=batch_size)\n",
    "# Deshacer la normalización\n",
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "trainYOriginal = scaler.inverse_transform([trainY])\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "testYOriginal = scaler.inverse_transform([testY])\n",
    "# Calcular los error\n",
    "trainScore = math.sqrt(mean_squared_error(trainYOriginal[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testYOriginal[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qSVz1FSXD1WH"
   },
   "source": [
    "Por último, podemos generar predicciones utilizando el modelo para el conjunto de datos de entrenamiento y de test para obtener una indicación visual de la habilidad del modelo.\n",
    "\n",
    "Debido a la forma en que se preparó el conjunto de datos, debemos desplazar las predicciones para que se alineen en el eje x con el conjunto de datos original. Una vez preparados, los datos se representan, mostrando el conjunto de datos original en azul, las predicciones del conjunto de datos de entrenamiento en verde y las predicciones del conjunto de datos de prueba no visto en rojo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "83IgA45VD1WH",
    "outputId": "0d74d2e2-024e-42e7-b61c-cc71176651cf"
   },
   "outputs": [],
   "source": [
    "# Hacer un shift de las predicciones de entrenamiento para el plot\n",
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "# Hacer un shift de las predicciones de test para el plot\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "\n",
    "# Representar las predicciones\n",
    "plt.title(\"Plot baseline and predictions\")\n",
    "plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IBPijESTD1WK"
   },
   "source": [
    "Como podemos ver, la red ha hecho un buen trabajo, aunque las predicciones empiezan a desviarse al final.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMgWULOS8b75"
   },
   "source": [
    "## Referencias\n",
    "\n",
    "Este material se ha basado en la entrada [\"Time Series Prediction with LSTM Recurrent Neural Networks in Python with Keras\"](https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/) de Machine Learning Mastery. Es muy recomendable consultar la entrada completa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eCiIqHg3D1WK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "time_series_data.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
