{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayrna/ap-ts-rnn/blob/main/series_temporales/time_series.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1gFaJvphYg3"
      },
      "source": [
        "# Series temporales en Python\n",
        "\n",
        "Vamos a utilizar fundamentalmente dos bibliotecas:\n",
        "\n",
        "- Pandas: https://pandas.pydata.org/pandas-docs/stable/timeseries.html\n",
        "- scipy http://www.statsmodels.org/devel/tsa.html\n",
        "\n",
        "## Estacionaridad\n",
        "\n",
        "Un serie temporal (ST) se dice que es estacionaria si sus propiedades estadísticas, tales como la media, la varianza y la covarianza, son constantes a lo largo del tiempo.\n",
        "\n",
        "- Media constante.\n",
        "- Varianza constante.\n",
        "- La covarianza entre dos instantes depende del número de observaciones que les separan, no del instante de tiempo.\n",
        "\n",
        "### ¿Que es lo que provoca la no estacionaridad de una ST?.\n",
        "\n",
        "Hay dos razones fundamentales:\n",
        "\n",
        "1. La tendencia -- La media varía a lo largo del tiempo. Por ejemplo, el número de pasajeros en general ha crecido conforme han ido pasando los años.\n",
        "\n",
        "2. Estacionalidad -- Variaciones que suceden en periodos específicos de tiempo. Por ejemplo, las personas pueden tener una tendencia a comprar coches en determinadas épocas del año o meses, debido a las pagas extras o a las vacaciones.\n",
        "\n",
        "## Estructura de una serie temporal en Pandas\n",
        "\n",
        "- Una ST es similar a una lista o un *array* en Python.\n",
        "- Representa una serie de valores (numéricos o de otro tipo) en forma de columna de datos.\n",
        "- Proporciona alguna funcionalidad adicional (métodos y operadores), que hacen que sea una versión más potente que una lista."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RTnjI7VhYg4"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-11T22:54:30.548232Z",
          "iopub.status.busy": "2020-10-11T22:54:30.546495Z",
          "iopub.status.idle": "2020-10-11T22:54:30.747034Z",
          "shell.execute_reply": "2020-10-11T22:54:30.746658Z"
        },
        "id": "nkmcfSzbhYg5"
      },
      "outputs": [],
      "source": [
        "# Crear una serie temporal a partir de una lista\n",
        "ser = pd.Series([1, 3])\n",
        "print(ser)\n",
        "\n",
        "# Usar una serie de cadenas como índice\n",
        "prices = {'apple': 4.99,\n",
        "         'banana': 1.99,\n",
        "         'orange': 3.99}\n",
        "ser = pd.Series(prices)\n",
        "print(ser)\n",
        "\n",
        "x = pd.Series(np.arange(1,3), index=[x for x in 'ab'])\n",
        "print(x)\n",
        "print(x['b'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXS_P0qOhYg6"
      },
      "source": [
        "## Análisis de series temporales a partir de Google Trends\n",
        "\n",
        "Inspirado en: https://www.datacamp.com/community/tutorials/time-series-analysis-tutorial\n",
        "\n",
        "Utilizaremos los datos de Google Trends de palabras clave como 'diet' y 'gim' para ver como varían a lo largo del tiempo, al mismo tiempo que aprendemos sobre tendencias y estacionalidad en datos de series temporales.\n",
        "\n",
        "Los datos se corresponden a una sesión del *Facebook Live code* del 4 de enero de 2018. Se comprueban los datos de Google Trends en referencia a 'diet', 'gym' y 'finance' con la idea de ver como varían en función del tiempo. Nos preguntamos si estos términos son más populares en enero, cuando estamos con los propósitos de año nuevo.\n",
        "\n",
        "En este tutorial vamos a:\n",
        "- Leer los datos\n",
        "- Recodificarlos\n",
        "- Realizar un análisis exploratorio de los mismos\n",
        "- Entrenar modelos predictivos\n",
        "\n",
        "## Leer los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-11T22:54:30.751722Z",
          "iopub.status.busy": "2020-10-11T22:54:30.751380Z",
          "iopub.status.idle": "2020-10-11T22:54:31.581302Z",
          "shell.execute_reply": "2020-10-11T22:54:31.580627Z"
        },
        "id": "svon87jjhYg6"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    url = \"https://raw.githubusercontent.com/datacamp/datacamp_facebook_live_ny_resolution/master/data/multiTimeline.csv\"\n",
        "    df = pd.read_csv(url, skiprows=2)\n",
        "except:\n",
        "    df = pd.read_csv(\"./data/multiTimeline.csv\", skiprows=2)\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "# Rename columns\n",
        "df.columns = ['month', 'diet', 'gym', 'finance']\n",
        "\n",
        "# Describe\n",
        "print(df.describe())\n",
        "\n",
        "print(df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0n9d4OtfhYg6"
      },
      "source": [
        "## Recodificar los datos\n",
        "\n",
        "Ahora, vamos a convertir la columna 'month' en un `DateTime` y hacer que sea el índice del `DataFrame`.\n",
        "\n",
        "Hacemos esto porque al ver el resultado del método `.info()` nos damos cuenta que la columna `month` es de tipo `object`. Este tipo genérico encapsula todo desde cadenas a enteros y esto no es lo que queremos cuando examinamos series temporales. Utilizaremos el método `.to_datetime()` para convertir la columna `month` del `DataFrame` a tipo `DateTime`.\n",
        "\n",
        "¡Ten cuidado! Haz uso del argumento `inplace` cuando estableces el índice del `DataFrame` de forma que los cambios se hagan realmente sobre la copia actual (y no se devuelva una copia modificada)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-11T22:54:31.589044Z",
          "iopub.status.busy": "2020-10-11T22:54:31.588587Z",
          "iopub.status.idle": "2020-10-11T22:54:31.591281Z",
          "shell.execute_reply": "2020-10-11T22:54:31.590810Z"
        },
        "id": "kZrIpAAzhYg7"
      },
      "outputs": [],
      "source": [
        "df.month = pd.to_datetime(df.month)\n",
        "df.set_index('month', inplace=True)\n",
        "\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hFSnK8chYg7"
      },
      "source": [
        "## Análisis exploratorio de los datos\n",
        "\n",
        "Puedes utilizar la herramienta de visualización de `pandas` `.plot()` para representar tus datos como 3 líneas en una sola figura (una para cada columna, `diet`, `gym` y `finance`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-11T22:54:31.595761Z",
          "iopub.status.busy": "2020-10-11T22:54:31.595158Z",
          "iopub.status.idle": "2020-10-11T22:54:31.770569Z",
          "shell.execute_reply": "2020-10-11T22:54:31.770879Z"
        },
        "id": "nPAvOIEQhYg8"
      },
      "outputs": [],
      "source": [
        "df.plot()\n",
        "plt.xlabel('Year');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sjwR9yZ7hYg9"
      },
      "outputs": [],
      "source": [
        "# Cambiar los parámetros de la figura\n",
        "df.plot(figsize=(20,10), linewidth=5, fontsize=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5962a0kthYg9"
      },
      "outputs": [],
      "source": [
        "# Representar solo una figura\n",
        "df[['diet']].plot(figsize=(20,10), linewidth=5, fontsize=20)\n",
        "plt.xlabel('Year', fontsize=20);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCd88po9hYg9"
      },
      "source": [
        "Ten en cuenta que estos datos son relativos. Como se puede leer en Google Trends:\n",
        "\n",
        "> Numbers represent search interest relative to the highest point on the chart\n",
        "> for the given region and time.\n",
        "> A value of 100 is the peak popularity for the term.\n",
        "> A value of 50 means that the term is half as popular.\n",
        "> Likewise a score of 0 means the term was less than 1% as popular as the peak.\n",
        "\n",
        "## Remuestreo, suavizado, obtención de ventanas, medias deslizantes: tendencias\n",
        "\n",
        "Las medias deslizantes toman, para cada instante de tiempo, la media de los puntos que le rodean. El número de puntos se especifica como un tamaño de ventana.\n",
        "\n",
        "Consultar el siguiente enlace http://pandas.pydata.org/pandas-docs/stable/timeseries.html\n",
        "\n",
        "El valor 'A' significa frecuencia anual (tomada a final de año)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-11T22:54:31.789823Z",
          "iopub.status.busy": "2020-10-11T22:54:31.789295Z",
          "iopub.status.idle": "2020-10-11T22:54:31.928058Z",
          "shell.execute_reply": "2020-10-11T22:54:31.927689Z"
        },
        "id": "doXBg1tqhYg-"
      },
      "outputs": [],
      "source": [
        "diet = df['diet']\n",
        "\n",
        "print(type(diet.resample('YE')))\n",
        "\n",
        "diet_resamp_yr = diet.resample('YE').mean()\n",
        "print(diet_resamp_yr.head())\n",
        "diet_roll_yr = diet.rolling(12).mean()\n",
        "print(diet_roll_yr.head(20))\n",
        "\n",
        "ax = diet.plot(alpha=0.5, style='-') # Guardamos los ejes (ax) para reutilizarlos en el resto de plots\n",
        "diet_resamp_yr.plot(style=':', label='Media anual de cada año', ax=ax)\n",
        "diet_roll_yr.plot(style='--', label='Media deslizante (más suave), tamaño de ventana=12', ax=ax)\n",
        "ax.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2HeK6ZshYg-"
      },
      "source": [
        "Podemos hacer la misma operación con `numpy`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-11T22:54:31.942206Z",
          "iopub.status.busy": "2020-10-11T22:54:31.941839Z",
          "iopub.status.idle": "2020-10-11T22:54:32.035139Z",
          "shell.execute_reply": "2020-10-11T22:54:32.034782Z"
        },
        "id": "6letQ1lkhYg-"
      },
      "outputs": [],
      "source": [
        "x = np.asarray(df[['diet']])\n",
        "win = 12\n",
        "win_half = int(win / 2)\n",
        "#print([((idx-win_half), (idx+win_half)) for idx in np.arange(win_half, len(x))])\n",
        "\n",
        "diet_smooth = np.array([x[(idx-win_half):(idx+win_half)].mean() for idx in np.arange(win_half, len(x))])\n",
        "# Ojo, no estamos saliendo de rango, pero es ignorado por numpy\n",
        "plt.plot(diet_smooth);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StkIlR8EhYg-"
      },
      "source": [
        "Hacemos un nuevo `DataFrame` que incluya la concatenación de los valores para `diet` y `gym` ya suavizados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-11T22:54:32.050686Z",
          "iopub.status.busy": "2020-10-11T22:54:32.050014Z",
          "iopub.status.idle": "2020-10-11T22:54:32.182726Z",
          "shell.execute_reply": "2020-10-11T22:54:32.182418Z"
        },
        "id": "5OXX1ouchYg-"
      },
      "outputs": [],
      "source": [
        "gym = df['gym']\n",
        "\n",
        "df_avg = pd.concat([diet.rolling(12).mean(), gym.rolling(12).mean()], axis=1)\n",
        "df_avg.plot()\n",
        "plt.xlabel('Year');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLYDdQcNhYg_"
      },
      "source": [
        "Eliminar la tendencia de la serie original."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-11T22:54:32.186189Z",
          "iopub.status.busy": "2020-10-11T22:54:32.185864Z",
          "iopub.status.idle": "2020-10-11T22:54:32.310269Z",
          "shell.execute_reply": "2020-10-11T22:54:32.310530Z"
        },
        "id": "A26yHR3JhYg_"
      },
      "outputs": [],
      "source": [
        "df_dtrend = df[[\"diet\", \"gym\"]] - df_avg\n",
        "df_dtrend.plot()\n",
        "plt.xlabel('Year');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqfMkQZ_hYg_"
      },
      "source": [
        "## Diferenciación de primer orden: patrones estacionales\n",
        "\n",
        "La diferenciación de primer orden nos permite eliminar la tendencia y ver solo los patrones estacionales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-11T22:54:32.315450Z",
          "iopub.status.busy": "2020-10-11T22:54:32.315070Z",
          "iopub.status.idle": "2020-10-11T22:54:32.472362Z",
          "shell.execute_reply": "2020-10-11T22:54:32.472074Z"
        },
        "id": "9zMhjuBKhYg_"
      },
      "outputs": [],
      "source": [
        "# diff = original - shiftted data\n",
        "print(diet.head())\n",
        "print(diet.shift().head()) # Serie con retardo de 1 (X_{t-1})\n",
        "print(diet.diff().head()) # Serie de diferencias de 1 (X_t-X_{t-1})\n",
        "assert np.all((diet.diff() == diet - diet.shift())[1:])\n",
        "\n",
        "df.diff().plot()\n",
        "plt.xlabel('Year');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6-rmpquhYhA"
      },
      "source": [
        "## Periodicidad y correlación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-11T22:54:32.475807Z",
          "iopub.status.busy": "2020-10-11T22:54:32.475474Z",
          "iopub.status.idle": "2020-10-11T22:54:32.617480Z",
          "shell.execute_reply": "2020-10-11T22:54:32.617146Z"
        },
        "id": "_kzSywnWhYhA"
      },
      "outputs": [],
      "source": [
        "df.plot()\n",
        "plt.xlabel('Year');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rw46fzUthYhA"
      },
      "source": [
        "Obtener la matriz de correlaciones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-11T22:54:32.629819Z",
          "iopub.status.busy": "2020-10-11T22:54:32.629454Z",
          "iopub.status.idle": "2020-10-11T22:54:32.734141Z",
          "shell.execute_reply": "2020-10-11T22:54:32.733779Z"
        },
        "id": "scnWWkMEhYhA"
      },
      "outputs": [],
      "source": [
        "print(df.corr())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vYN01ay2hYhB"
      },
      "source": [
        "¡`diet` y `gym` tienen una correlación negativa!\n",
        "Recuerda que tienes un componente estacional y uno de tendencia.\n",
        "\n",
        "- Los componentes de tendencia parecen estar negativamente correlados.\n",
        "- Los componentes estacionales estaría positivamente correlados.\n",
        "\n",
        "En realidad, al estar trabajando sobre la serie original, estamos viendo las correlaciones al mismo tiempo.\n",
        "\n",
        "Correlación estacional: correlación de las diferencias de primer orden de estas STs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-11T22:54:32.747657Z",
          "iopub.status.busy": "2020-10-11T22:54:32.746992Z",
          "iopub.status.idle": "2020-10-11T22:54:32.871390Z",
          "shell.execute_reply": "2020-10-11T22:54:32.871066Z"
        },
        "id": "YeQq-xNjhYhB"
      },
      "outputs": [],
      "source": [
        "df.diff().plot()\n",
        "plt.xlabel('Year');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdYy1lHHhYhB"
      },
      "source": [
        "La matriz de correlación es ahora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-11T22:54:32.883942Z",
          "iopub.status.busy": "2020-10-11T22:54:32.883586Z",
          "iopub.status.idle": "2020-10-11T22:54:32.988231Z",
          "shell.execute_reply": "2020-10-11T22:54:32.987898Z"
        },
        "id": "daWmzHwIhYhB"
      },
      "outputs": [],
      "source": [
        "print(df.diff().corr())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfQvTWNdhYhB"
      },
      "source": [
        "Para verlo todo mucho más claro, podemos usar el método `seasonal_decompose` que descompone la serie en sus componentes estacional, de tendencia y residual."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-11T22:54:32.992192Z",
          "iopub.status.busy": "2020-10-11T22:54:32.991770Z",
          "iopub.status.idle": "2020-10-11T22:54:33.411002Z",
          "shell.execute_reply": "2020-10-11T22:54:33.410641Z"
        },
        "id": "9go7zkWQhYhB"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "\n",
        "x = gym\n",
        "\n",
        "x = x.astype(float) # force float\n",
        "decomposition = seasonal_decompose(x)\n",
        "trend = decomposition.trend\n",
        "seasonal = decomposition.seasonal\n",
        "residual = decomposition.resid\n",
        "\n",
        "plt.subplot(411)\n",
        "plt.plot(x, label='Original')\n",
        "plt.legend(loc='best')\n",
        "plt.subplot(412)\n",
        "plt.plot(trend, label='Trend')\n",
        "plt.legend(loc='best')\n",
        "plt.subplot(413)\n",
        "plt.plot(seasonal,label='Seasonality')\n",
        "plt.legend(loc='best')\n",
        "plt.subplot(414)\n",
        "plt.plot(residual, label='Residuals')\n",
        "plt.legend(loc='best')\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogFNboythYhC"
      },
      "source": [
        "Podemos hacer el plot directamente a partir del objeto asociado a la descomposición:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBN_PM7XhYhC"
      },
      "outputs": [],
      "source": [
        "fig = decomposition.plot()\n",
        "fig.set_size_inches(14,7)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ME3Be_XVhYhC"
      },
      "source": [
        "## Comprobar la estacionariedad\n",
        "\n",
        "El método que podemos ver a continuación representa los estadísticos (media y varianza) en ventana deslizante para comprobar de forma cómoda si la varianza tiende a cambiar a lo largo del tiempo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3NgCc_ehYhC"
      },
      "outputs": [],
      "source": [
        "### Representar los estadísticos para comprobar la estacionariedad\n",
        "def test_stationarity(timeseries, title):\n",
        "\n",
        "    # Determinar los estadísticos\n",
        "    rolmean = pd.Series(timeseries).rolling(window=12).mean()\n",
        "    rolstd = pd.Series(timeseries).rolling(window=12).std()\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(16, 4))\n",
        "    ax.plot(timeseries, label= title)\n",
        "    ax.plot(rolmean, label='media deslizante');\n",
        "    ax.plot(rolstd, label='desviación típica deslizante (x10)');\n",
        "    ax.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikH-1KgThYhC"
      },
      "outputs": [],
      "source": [
        "pd.options.display.float_format = '{:.8f}'.format\n",
        "test_stationarity(diet,'raw data')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWU5rmxGhYhC"
      },
      "source": [
        "A simple vista no parece que la desviación típica o la media cambien demasiado, pero sería más correcto realizar este estudio usando algún test estadístico, ya que los cambios pueden no ser evidentes debido a la escala del gráfico.\n",
        "\n",
        "### Test estadístico Augmented Dickey-Fuller (ADF)\n",
        "\n",
        "El enfoque ADF es esencialmente una prueba de significación estadística que compara el valor $p$ con los valores críticos y realiza pruebas de hipótesis. Mediante esta prueba, podemos determinar si los datos procesados son estacionarios o no con diferentes niveles de confianza."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkwswJ42hYhC"
      },
      "outputs": [],
      "source": [
        "# Augmented Dickey-Fuller Test\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "\n",
        "def ADF_test(timeseries, dataDesc):\n",
        "    print(' > ¿Es estacionaria la serie {}?'.format(dataDesc))\n",
        "    dftest = adfuller(timeseries.dropna(), autolag='AIC')\n",
        "    print('Estadístico = {:.3f}'.format(dftest[0]))\n",
        "    print('P-value = {:.3f}'.format(dftest[1]))\n",
        "    print('Valores críticos :')\n",
        "    for k, v in dftest[4].items():\n",
        "        print('\\t{}: {} - La serie es {} estacionaria con una confianza de {}%'.format(k, v, 'no' if v<dftest[0] else '', 100-int(k[:-1])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlOcZDighYhC"
      },
      "outputs": [],
      "source": [
        "ADF_test(diet,'Datos originales')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOo_LMr2hYhD"
      },
      "source": [
        "Para intentar hacer la serie estacionaria, podemos restar la media deslizante y dividir por la desviación típica deslizante:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoKwAMy8hYhD"
      },
      "outputs": [],
      "source": [
        "# Eliminar tendencia\n",
        "diet_detrend =  (diet - diet.rolling(window=12).mean())/diet.rolling(window=12).std()\n",
        "\n",
        "test_stationarity(diet_detrend,'datos sin tendencia')\n",
        "ADF_test(diet_detrend,'datos sin tendencia')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5yG3brOhYhD"
      },
      "source": [
        "Aún así no conseguimos estacionariedad. El problema es que aún tenemos la parte estacional. Una forma de eliminarla es realizar una diferenciación utilizando el periodo correspondiente a la estacionalidad (12 meses en este caso)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsvYII45hYhD"
      },
      "outputs": [],
      "source": [
        "# Differencing\n",
        "diet_12lag =  diet - diet.shift(12)\n",
        "\n",
        "test_stationarity(diet_12lag,'datos con retardo de 12 instantes')\n",
        "ADF_test(diet_12lag,'datos con retardo de 12 instantes')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oVHabaChYhD"
      },
      "source": [
        "Seguimos sin obtener una serie estacionaria, porque aún está la tendencia (observa como la media fluctúa bastante). Lo que hay que hacer es combinar las dos técnicas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpovRoJthYhD"
      },
      "outputs": [],
      "source": [
        "# Eliminar tendencia y diferenciar\n",
        "\n",
        "diet_12lag_detrend =  diet_detrend - diet_detrend.shift(12)\n",
        "\n",
        "test_stationarity(diet_12lag_detrend,'12 lag differenced de-trended data')\n",
        "ADF_test(diet_12lag_detrend,'12 lag differenced de-trended data')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HmMKk3OhYhE"
      },
      "source": [
        "## Autocorrelación\n",
        "\n",
        "Una ST se dice que es periódica si se repite en intervalos equiespaciados en el tiempo, por ejemplo, cada 12 meses.\n",
        "\n",
        "La función de autocorrelación (ACF) es una medida de la correlación entre la ST con una versión retardada de la misma. Por ejemplo, si tomamos lag=5, ACF compararía los instantes t6, t7, t8... de la ST con t1, t2, t3...\n",
        "\n",
        "Existe una función de `pandas` que nos hace una representación de estos valores de autocorrelación:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-11T22:54:33.423884Z",
          "iopub.status.busy": "2020-10-11T22:54:33.422998Z",
          "iopub.status.idle": "2020-10-11T22:54:33.528721Z",
          "shell.execute_reply": "2020-10-11T22:54:33.528367Z"
        },
        "id": "2VpzHIoEhYhE"
      },
      "outputs": [],
      "source": [
        "# from pandas.plotting import autocorrelation_plot\n",
        "from pandas.plotting import autocorrelation_plot\n",
        "\n",
        "x = df[\"diet\"].astype(float)\n",
        "autocorrelation_plot(x);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkeHcbR7hYhE"
      },
      "source": [
        "También podemos calcular los valores de ACF:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-11T22:54:33.531380Z",
          "iopub.status.busy": "2020-10-11T22:54:33.531012Z",
          "iopub.status.idle": "2020-10-11T22:54:33.671755Z",
          "shell.execute_reply": "2020-10-11T22:54:33.671428Z"
        },
        "id": "-evPND5QhYhE"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.stattools import acf\n",
        "\n",
        "x_diff = x.diff().dropna() # El primer término será NA\n",
        "lag_acf = acf(x_diff, nlags=36, fft=True)\n",
        "plt.plot(lag_acf)\n",
        "plt.title('Autocorrelation Function')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPbYYzZ6hYhE"
      },
      "source": [
        "Como se puede observar, el gráfico ACF tiene picos cada 12 meses, lo que quiere decir que la serie está correlada consigo misma de forma anual (enero con enero, febrero con febrero...)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fu9NXzRhhYhF"
      },
      "source": [
        "## División en conjuntos de entrenamiento y test\n",
        "\n",
        "Para estar preparado para evaluar el rendimiento de los modelos que se están considerando para su análisis de series temporales, es importante dividir el conjunto de datos en al menos dos partes.\n",
        "\n",
        "Una parte será el conjunto de datos de 'Entrenamiento', y la otra parte será el conjunto de datos de 'Test'. A veces se crea un tercer conjunto de datos o un conjunto de datos de 'Validación' que reserva algunos datos para pruebas adicionales.\n",
        "\n",
        "Para los propósitos de este ejemplo de análisis de series de tiempo, solo tendremos entrenamiento y test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f71edrcshYhF"
      },
      "outputs": [],
      "source": [
        "predict_date='2016-01-01'\n",
        "diet_to_train = diet[:predict_date] # Datos de entrenamiento (todos los años salvo los dos últimos)\n",
        "diet_to_test = diet[predict_date:] # Dos últimos años para test\n",
        "predict_length = len(diet) - len(diet[:predict_date]) # Número de datos en test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpJPmKzdhYhF"
      },
      "source": [
        "## Suavizado exponencial simple (SES)\n",
        "\n",
        "Adecuado para datos de series temporales sin componentes de tendencia o estacionales.\n",
        "\n",
        "Este modelo calcula los datos de previsión utilizando medias ponderadas. Un parámetro importante que utiliza este modelo es el parámetro de suavizado: $\\alpha$, eligiéndose un valor entre 0 y 1 para determinar el nivel de suavizado. Cuando $\\alpha=0$, las previsiones son iguales a la media de los datos históricos.Cuando $\\alpha=1$, las previsiones serán iguales al valor de la última observación.\n",
        "\n",
        "Puede elegir un $\\alpha$ específico (por ejemplo, en el código de muestra, utilizaremos $\\alpha=0.8$) o utilizar el módulo 'statsmodels' de Python para encontrar automáticamente un valor optimizado para el conjunto de datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLpXW8vBhYhF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from statsmodels.tsa.api import SimpleExpSmoothing\n",
        "\n",
        "def ses(y, y_to_train,y_to_test,smoothing_level,predict_length):\n",
        "    y.plot(marker='o', color='black', legend=True, figsize=(14, 7))\n",
        "\n",
        "    fit1 = SimpleExpSmoothing(y_to_train).fit(smoothing_level=smoothing_level,optimized=False)\n",
        "    fcast1 = fit1.forecast(predict_length).rename(r'$\\alpha={}$'.format(smoothing_level))\n",
        "    # Valor de alpha fijo\n",
        "    fcast1.plot(marker='o', color='blue', legend=True)\n",
        "    fit1.fittedvalues.plot(marker='o',  color='blue')\n",
        "    mse1 = ((fcast1 - y_to_test) ** 2).mean()\n",
        "    print('El error cuadrático medio con las predicciones para alpha={} es {}'.format(smoothing_level,round(np.sqrt(mse1), 2)))\n",
        "\n",
        "    ## auto optimization\n",
        "    fit2 = SimpleExpSmoothing(y_to_train).fit()\n",
        "    fcast2 = fit2.forecast(predict_length).rename(r'$\\alpha=%s$'%fit2.model.params['smoothing_level'])\n",
        "    # plot\n",
        "    fcast2.plot(marker='o', color='green', legend=True)\n",
        "    fit2.fittedvalues.plot(marker='o', color='green')\n",
        "\n",
        "    mse2 = ((fcast2 - y_to_test) ** 2).mean()\n",
        "    print('El error cuadrático medio con las predicciones para alpha automático es {}'.format(round(np.sqrt(mse2), 2)))\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DK0oNQs1hYhF"
      },
      "outputs": [],
      "source": [
        "ses(diet, diet_to_train,diet_to_test,0.8,predict_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dEVy938hYhG"
      },
      "source": [
        "La visualización de los resultados del modelo de previsión de suavizado exponencial simple (SES) muestra la diferencia entre el $\\alpha$ especificado (línea azul) y el $\\alpha$ autooptimizado (línea verde). Como se puede ver en el gráfico, SES predice una línea de previsión plana, ya que la lógica detrás de ella utiliza promedios ponderados. Aunque el RMSE es bajo, no predice ninguna fluctuación. Dado que la mayoría de los datos de las series temporales tienen algún tipo de tendencia o estacionalidad, este modelo puede utilizarse para obtener una línea de base para la comparación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZbeAzyxhYhG"
      },
      "source": [
        "## Método de tendencia lineal de Holt\n",
        "\n",
        "Adecuado para datos de series temporales con una componente de tendencia pero sin una componente estacional.\n",
        "\n",
        "Ampliando el método SES, el método Holt le ayuda a pronosticar datos de series temporales que tienen una tendencia. Además del parámetro de suavización de nivel $\\alpha$ introducido con el método SES, el método Holt añade el parámetro de suavización de tendencia $\\beta$. Al igual que con el parámetro $\\alpha$, el rango de $\\beta$ también está entre 0 y 1.\n",
        "\n",
        "El código de ejemplo que aparece a continuación contiene dos variantes diferentes dentro del método Holt. Ambos ajustes tienen como valores de los parámetros $\\alpha=0.6$, $\\beta=0.2$. El ajuste1 (`fit1`) es el modelo aditivo de Holt por defecto, y el ajuste2 (`fit2`) es un modelo exponencial. Un modelo exponencial sería apropiado para situaciones en las que el aumento o la disminución comienzan lentamente pero luego se aceleran rápidamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9P7FKcsBhYhG"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.api import Holt\n",
        "\n",
        "def holt(y,y_to_train,y_to_test,smoothing_level,smoothing_slope, predict_length):\n",
        "    y.plot(marker='o', color='black', legend=True, figsize=(14, 7))\n",
        "\n",
        "    fit1 = Holt(y_to_train).fit(smoothing_level, smoothing_slope, optimized=False)\n",
        "    fcast1 = fit1.forecast(predict_length).rename(\"Modelo de tendencia lineal de Holt\")\n",
        "    mse1 = ((fcast1 - y_to_test) ** 2).mean()\n",
        "    print('El error cuadrático medio del modelo de tendencia lineal de Holt es {}'.format(round(np.sqrt(mse1), 2)))\n",
        "\n",
        "    fit2 = Holt(y_to_train, exponential=True).fit(smoothing_level, smoothing_slope, optimized=False)\n",
        "    fcast2 = fit2.forecast(predict_length).rename(\"Modelo de tendencia exponencial de Holt\")\n",
        "    mse2 = ((fcast2 - y_to_test) ** 2).mean()\n",
        "    print('El error cuadrático medio del modelo de tendencia exponencial de Holt es {}'.format(round(np.sqrt(mse2), 2)))\n",
        "\n",
        "    fit1.fittedvalues.plot(marker=\"o\", color='blue')\n",
        "    fcast1.plot(color='blue', marker=\"o\", legend=True)\n",
        "    fit2.fittedvalues.plot(marker=\"o\", color='red')\n",
        "    fcast2.plot(color='red', marker=\"o\", legend=True)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdXRYzbzhYhG"
      },
      "outputs": [],
      "source": [
        "holt(diet, diet_to_train,diet_to_test,0.6,0.2,predict_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TA9xCft7hYhH"
      },
      "source": [
        "Al observar la visualización del método Holt, vemos cómo la tendencia lineal (línea azul) y la tendencia exponencial (línea roja) se comparan entre sí. En comparación con SES, Holt capta más la tendencia de los datos. Sin embargo, como se puede ver en el gráfico, la tendencia que descubre es demasiado dramática y sería muy poco probable que tuviera lugar en la vida real."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmfMQDqghYhH"
      },
      "source": [
        "## Método estacional de Holt-Winters\n",
        "Adecuado para datos de series temporales con componentes de tendencia y/o estacional.\n",
        "\n",
        "El modelo de Holt-Winters amplía al de Holt para permitir la previsión de datos de series temporales que tienen tanto tendencia como estacionalidad. Así, incluimos un parámetro de suavización de la estacionalidad: $\\gamma$.\n",
        "\n",
        "Hay dos tipos generales de estacionalidad: Aditiva y Multiplicativa.\n",
        "- *Aditiva*: `x = Tendencia + Estacionalidad + Aleatorio`. Los cambios estacionales en los datos se mantienen más o menos igual a lo largo del tiempo y no fluctúan en relación con los datos globales.\n",
        "- *Multiplicativa*:`xt = Tendencia * Estacional * Aleatorio`. La variación estacional cambia en relación con los cambios generales de los datos. Así, si los datos tienen una tendencia al alza, las diferencias estacionales también crecen proporcionalmente.\n",
        "\n",
        "Esta es imagen es muy útil:\n",
        "![Imagen que muestra los gráficos aditivos VS multiplicativos](https://github.com/ayrna/ap2122/blob/main/series_temporales/pics/additive-vs-multiplicative.png?raw=1)\n",
        "Fuente: [Sigmundo Preissler Jr, PhD](https://medium.com/@sigmundojr/seasonality-in-python-additive-or-multiplicative-model-d4b9cf1f48a7)\n",
        "\n",
        "Una vez que sepamos que tipo de estacionalidad tienen nuestros datos, debemos identificar el periodo de la estacionalidad o $s$. En nuestro caso, como ya vimos, la estacionalidad tiene periodo $s=12$ meses.\n",
        "\n",
        "El módulo Python `statsmodels` proporciona a los usuarios una gama de combinaciones de parámetros basados en los tipos de tendencia, tipos de estacionalidad y otras opciones para hacer transformaciones Box-Cox. Este paquete es algo así como la versión de series de tiempo de la búsqueda Grid para el ajuste de hiperparámetros. Para saber más, consultad esta [documentación](https://www.statsmodels.org/dev/generated/statsmodels.tsa.holtwinters.ExponentialSmoothing.html) y esta [explicación detallada](https://otexts.com/fpp2/holt-winters.html) que nos ayuda a elegir lo que mejor se adapta a los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTQHPf8shYhH"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.api import ExponentialSmoothing\n",
        "\n",
        "def holt_win_sea(y,y_to_train,y_to_test,seasonal_type,seasonal_period,predict_length):\n",
        "\n",
        "    y.plot(marker='o', color='black', legend=True, figsize=(14, 7))\n",
        "\n",
        "    if seasonal_type == 'additive':\n",
        "        fit1 = ExponentialSmoothing(y_to_train, seasonal_periods = seasonal_period, trend='add', seasonal='add', use_boxcox=True).fit()\n",
        "        fcast1 = fit1.forecast(predict_length).rename('Aditiva')\n",
        "        mse1 = ((fcast1 - y_to_test) ** 2).mean()\n",
        "        print('Error cuadrático medio de una tendencia aditiva, estacionalidad aditiva con '+\n",
        "              'un periodo season_length={} y una transformación Box-Cox {}'.format(seasonal_period,round(np.sqrt(mse1), 2)))\n",
        "\n",
        "        fit2 = ExponentialSmoothing(y_to_train, seasonal_periods = seasonal_period, trend='add', seasonal='add', damped=True, use_boxcox=True).fit()\n",
        "        fcast2 = fit2.forecast(predict_length).rename('Aditiva amortiguada')\n",
        "        mse2 = ((fcast2 - y_to_test) ** 2).mean()\n",
        "        print('Error cuadrático medio de una tendencia aditiva amortiguada, estacionalidad aditiva con '+\n",
        "              'un periodo season_length={} y una transformación Box-Cox {}'.format(seasonal_period,round(np.sqrt(mse2), 2)))\n",
        "\n",
        "        fit1.fittedvalues.plot(style='--', color='red')\n",
        "        fcast1.plot(style='--', marker='o', color='red', legend=True)\n",
        "        fit2.fittedvalues.plot(style='--', color='green')\n",
        "        fcast2.plot(style='--', marker='o', color='green', legend=True)\n",
        "\n",
        "    elif seasonal_type == 'multiplicative':\n",
        "        fit3 = ExponentialSmoothing(y_to_train, seasonal_periods = seasonal_period, trend='add', seasonal='mul', use_boxcox=True).fit()\n",
        "        fcast3 = fit3.forecast(predict_length).rename('Multiplicativa')\n",
        "        mse3 = ((fcast3 - y_to_test) ** 2).mean()\n",
        "        print('Error cuadrático medio de una tendencia aditiva, estacionalidad multiplicativa con '+\n",
        "              'un periodo season_length={} y una transformación Box-Cox {}'.format(seasonal_period,round(np.sqrt(mse3), 2)))\n",
        "\n",
        "        fit4 = ExponentialSmoothing(y_to_train, seasonal_periods = seasonal_period, trend='add', seasonal='mul', damped=True, use_boxcox=True).fit()\n",
        "        fcast4 = fit4.forecast(predict_length).rename('Multiplicativa amortiguada')\n",
        "        mse4 = ((fcast3 - y_to_test) ** 2).mean()\n",
        "        print('Error cuadrático medio de una tendencia aditiva amortiguada, estacionalidad multiplicativa con '+\n",
        "              'un periodo season_length={} y una transformación Box-Cox {}'.format(seasonal_period,round(np.sqrt(mse4), 2)))\n",
        "\n",
        "        fit3.fittedvalues.plot(style='--', color='red')\n",
        "        fcast3.plot(style='--', marker='o', color='red', legend=True)\n",
        "        fit4.fittedvalues.plot(style='--', color='green')\n",
        "        fcast4.plot(style='--', marker='o', color='green', legend=True)\n",
        "\n",
        "    else:\n",
        "        print('Tipo estacional inválido. Escoger entre \\'additive\\' o \\'multiplicative\\'')\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ONneaM9hYhH"
      },
      "outputs": [],
      "source": [
        "holt_win_sea(diet, diet_to_train,diet_to_test,'additive',12, predict_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7M8SHDqhYhI"
      },
      "source": [
        "\n",
        "## Predicción de series temporales utilizando modelos AutoRegressive Moving Average (ARMA)\n",
        "\n",
        "Inspirado en:\n",
        "\n",
        "- https://www.packtpub.com/mapt/book/big_data_and_business_intelligence/9781783553358/7/ch07lvl1sec77/arma-models\n",
        "\n",
        "- http://en.wikipedia.org/wiki/Autoregressive%E2%80%93moving-average_model\n",
        "\n",
        "- ARIMA: https://www.analyticsvidhya.com/blog/2016/02/time-series-forecasting-codes-python/\n",
        "\n",
        "Mientras que los modelos de suavización exponencial utilizan medias ponderadas de observaciones pasadas para predecir nuevos valores, los modelos de AR y MA tienen en cuenta las autocorrelaciones o las correlaciones de serie temporal. En otras palabras, los modelos ARMA examinan las diferencias entre los valores de las series temporales.\n",
        "\n",
        "Los modelos ARMA se suelen utilizar a menudo como herramienta para predecir valores de un ST.\n",
        "Estos modelos combinan una parte AutoRegresiva (AR) con una parte de medias móviles (Moving Average, MA).\n",
        "En los modelos MA, asumimos que una variable es la suma de la media de la serie temporal y una combinación lineal de componentes de ruido.\n",
        "\n",
        "Los modelos AR y MA pueden tener distinto orden. En general, podemos definir un modelo ARMA con $p$ términos autorregresivos y $q$ términos de medias móviles de la siguiente forma:\n",
        "\n",
        "$$\n",
        "X_t = \\sum_i^p \\phi_i X_{t-i} +\\sum_i^q \\theta_i a_{t-i} + a_t\n",
        "$$\n",
        "\n",
        "### Eligiendo $p$ y $q$\n",
        "\n",
        "Lo primero que deberíamos hacer es representar las funciones de correlación parcial (PACF) para $p$ y las funciones de correlación (ACF) para $q$.\n",
        "\n",
        "La función de autocorrelación parcial (PACF) mide la correlación entre la ST en una versión retardada de sí misma pero eliminando antes la varianza ya explicada por retardos anteriores. Por ejemplo, si medimos el PACF para un $lag=5$ tendremos en cuenta la correlación con los valores de la serie de hace 5 instantes de tiempo, pero eliminando la varianza ya explicada por los restardos 1, 2, 3 y 4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-11T22:54:33.729989Z",
          "iopub.status.busy": "2020-10-11T22:54:33.719116Z",
          "iopub.status.idle": "2020-10-11T22:54:33.907163Z",
          "shell.execute_reply": "2020-10-11T22:54:33.906812Z"
        },
        "id": "U9bSHlGUhYhI"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.stattools import acf, pacf\n",
        "\n",
        "x = df[\"gym\"].astype(float)\n",
        "\n",
        "x_diff = x.diff().dropna() # El primer término será NA\n",
        "\n",
        "# Valores ACF y PACF:\n",
        "lag_acf = acf(x_diff, nlags=20, fft=True)\n",
        "lag_pacf = pacf(x_diff, nlags=20, method='ols')\n",
        "\n",
        "#Plot ACF:\n",
        "plt.subplot(121)\n",
        "plt.plot(lag_acf)\n",
        "plt.axhline(y=0,linestyle='--',color='gray')\n",
        "plt.axhline(y=-1.96/np.sqrt(len(x_diff)),linestyle='--',color='gray')\n",
        "plt.axhline(y=1.96/np.sqrt(len(x_diff)),linestyle='--',color='gray')\n",
        "plt.title('ACF (elegimos q=1)')\n",
        "\n",
        "#Plot PACF:\n",
        "plt.subplot(122)\n",
        "plt.plot(lag_pacf)\n",
        "plt.axhline(y=0,linestyle='--',color='gray')\n",
        "plt.axhline(y=-1.96/np.sqrt(len(x_diff)),linestyle='--',color='gray')\n",
        "plt.axhline(y=1.96/np.sqrt(len(x_diff)),linestyle='--',color='gray')\n",
        "plt.title('PACF (elegimos p=1)')\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2mz2q0XhYhI"
      },
      "source": [
        "En este gráfico, las dos líneas discontinuas a ambos lados del 0 son intervalos de confianza. Estos intervalos se usan para seleccionar $p$ y $q$ de la siguiente forma:\n",
        "\n",
        "- $p$: elegir el valor del desfase a partir del cual el PACF cruza el valor superior del intervalo de confianza la primera vez. En este caso $p=1$.\n",
        "\n",
        "- $q$: elegir el valor del desfase a partir del cual el ACF cruza el valor superior del intervalo de confianza la primera vez. En este caso $q=1$.\n",
        "\n",
        "### Entrenar un modelos ARMA con statsmodels\n",
        "\n",
        "1. Definir el modelo llamando a `ARMA()` y dándole los valores de $p$ y de $q$.\n",
        "\n",
        "2. Entrenar el modelo usando el conjunto de entrenamiento a partir del método `fit()`.\n",
        "\n",
        "3. Realizar las predicciones llamando a `predict()` el índice de los instantes de tiempo a predecir."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-10-11T22:54:33.910475Z",
          "iopub.status.busy": "2020-10-11T22:54:33.910118Z",
          "iopub.status.idle": "2020-10-11T22:54:34.200169Z",
          "shell.execute_reply": "2020-10-11T22:54:34.199836Z"
        },
        "id": "SBSigdQuhYhI"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "\n",
        "# Modelo más general Seasonal ARIMA multiplicativo SARIMAX(p,d,q)x(P,D,Q,s)\n",
        "# order=(p,d,q) seasonal_order(P,D,Q,s)\n",
        "model = ARIMA(x, order=(1, 0, 1), seasonal_order=(0,0,0,0)).fit() # fit model\n",
        "\n",
        "print(model.summary())\n",
        "plt.plot(x)\n",
        "plt.plot(model.predict(), color='red')\n",
        "plt.title('RSS: %.4f'% sum((model.fittedvalues-x)**2));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVyFgFEAhYhJ"
      },
      "source": [
        "## Modelos SARIMA\n",
        "\n",
        "Adecuados para datos de series temporales con componentes de tendencia y/o estacionales.\n",
        "\n",
        "SARIMA se basa en el concepto de ARIMA pero lo amplía para modelar las componentes estacionales de los datos. Observaréis que SARIMA incluye varios parámetros que pueden ajustarse para lograr un rendimiento óptimo. Podéis obtener más información sobre estos parámetros [aquí](https://machinelearningmastery.com/sarima-for-time-series-forecasting-in-python/). Son los siguientes:\n",
        "- Elementos de tendencia:\n",
        "\n",
        "   - $p$: Orden de autoregresión de tendencia.\n",
        "   - $d$: Orden de diferencia de tendencia.\n",
        "   - $q$: Orden de media móvil de tendencia.\n",
        "\n",
        "- Elementos estacionales:\n",
        "   - $P$: Orden de autorregresión estacional.\n",
        "   - $D$: Orden de diferencia estacional.\n",
        "   - $Q$: Orden de media móvil estacional.\n",
        "\n",
        "- $s$: Periodo para la parte estacional.\n",
        "\n",
        "Para obtener la mejor predicción, es importante encontrar los valores de $SARIMA(p,d,q)(P,D,Q)s$ que optimicen una métrica de interés. Para los propósitos de este tutorial, utilizaremos una \"búsqueda en cuadrícula\" para explorar iterativamente diferentes combinaciones de parámetros.\n",
        "\n",
        "La métrica de evaluación que utilizaremos para la búsqueda en la cuadrícula es el valor AIC (Criterio de Información de Akaike). El AIC mide lo bien que un modelo se ajusta a los datos teniendo en cuenta la complejidad general del modelo. En general, queremos elegir la combinación con el valor AIC más bajo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9O0ztc5ehYhJ"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "import statsmodels.api as sm\n",
        "import warnings\n",
        "\n",
        "# Ignoramos los warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def sarima_grid_search(y,seasonal_period):\n",
        "    p = d = q = range(0, 2)\n",
        "    pdq = list(itertools.product(p, d, q))\n",
        "    seasonal_pdq = [(x[0], x[1], x[2],seasonal_period) for x in list(itertools.product(p, d, q))]\n",
        "\n",
        "    mini = float('+inf')\n",
        "\n",
        "\n",
        "    for param in pdq:\n",
        "        for param_seasonal in seasonal_pdq:\n",
        "            mod = sm.tsa.statespace.SARIMAX(y,\n",
        "                                            order=param,\n",
        "                                            seasonal_order=param_seasonal,\n",
        "                                            enforce_stationarity=False,\n",
        "                                            enforce_invertibility=False)\n",
        "            try:\n",
        "                mod = sm.tsa.statespace.SARIMAX(y,\n",
        "                                                order=param,\n",
        "                                                seasonal_order=param_seasonal,\n",
        "                                                enforce_stationarity=False,\n",
        "                                                enforce_invertibility=False)\n",
        "\n",
        "                results = mod.fit(disp=False)\n",
        "\n",
        "                if results.aic < mini:\n",
        "                    mini = results.aic\n",
        "                    param_mini = param\n",
        "                    param_seasonal_mini = param_seasonal\n",
        "\n",
        "                print('SARIMA{}x{} - AIC:{}'.format(param, param_seasonal, results.aic))\n",
        "            except:\n",
        "                print(param)\n",
        "                print(param_seasonal)\n",
        "                continue\n",
        "    print('El conjunto de parámetros con mínimo AIC es: SARIMA{}x{} - AIC:{}'.format(param_mini, param_seasonal_mini, mini))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbQYZGvkhYhJ"
      },
      "outputs": [],
      "source": [
        "sarima_grid_search(diet_to_train,12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQii_ZPXhYhJ"
      },
      "source": [
        "Parece que la combinación de parámetros óptima es `SARIMA(0, 1, 1)x(1, 1, 1, 12)` (menor valor de AIC). Así que vamos a usarla para terminar de entrenar el modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grDKJ3JshYhJ"
      },
      "outputs": [],
      "source": [
        "# Llamar a esta función después de obtener la mejor combinación de parámetros en función del AIC\n",
        "def sarima_eva(y,order,seasonal_order,seasonal_period,pred_date,y_to_test):\n",
        "    # Entrenar el modelo\n",
        "    mod = sm.tsa.statespace.SARIMAX(y,\n",
        "                                order=order,\n",
        "                                seasonal_order=seasonal_order,\n",
        "                                enforce_stationarity=False,\n",
        "                                enforce_invertibility=False)\n",
        "\n",
        "    results = mod.fit()\n",
        "    print(results.summary().tables[1])\n",
        "\n",
        "    results.plot_diagnostics(figsize=(16, 8))\n",
        "    plt.show()\n",
        "\n",
        "    # El argumento dynamic=False asegura que realizamos predicciones a un instante de tiempo,\n",
        "    # de manera que para cada punto usamos todas las observaciones disponibles hasta ese punto.\n",
        "    # Con dynamic=Fecha las predicciones de la fase de test se construyen en base a las propias\n",
        "    # predicciones del modelo (no en base a los valores observados)\n",
        "    pred = results.get_prediction(start=pd.to_datetime(pred_date), dynamic=False)\n",
        "    pred_ci = pred.conf_int()\n",
        "    y_forecasted = pred.predicted_mean\n",
        "    mse = ((y_forecasted - y_to_test) ** 2).mean()\n",
        "    print('El RMSE de un modelo SARIMA con season_length={} y dynamic = False es {}'.format(seasonal_period,round(np.sqrt(mse), 2)))\n",
        "\n",
        "    ax = y.plot(label='observado')\n",
        "    y_forecasted.plot(ax=ax, label='Predicciones en base a valores observados', alpha=.7, figsize=(14, 7))\n",
        "    ax.fill_between(pred_ci.index,\n",
        "                    pred_ci.iloc[:, 0],\n",
        "                    pred_ci.iloc[:, 1], color='k', alpha=.2)\n",
        "\n",
        "    ax.set_xlabel('Fecha')\n",
        "    ax.set_ylabel('Trend')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # Una mejor idea de la capacidad predictiva puede obtenerse usando predicciones dinámicas.\n",
        "    # En este caso solo usamos las observaciones hasta un determinado instante temporal y\n",
        "    # después las predicciones se generan a partir de predicciones pasadas.\n",
        "    pred_dynamic = results.get_prediction(start=pd.to_datetime(pred_date), dynamic=True, full_results=True)\n",
        "    pred_dynamic_ci = pred_dynamic.conf_int()\n",
        "    y_forecasted_dynamic = pred_dynamic.predicted_mean\n",
        "    mse_dynamic = ((y_forecasted_dynamic - y_to_test) ** 2).mean()\n",
        "    print('El RMSE de un modelo SARIMA con season_length={} y dynamic = True es {}'.format(seasonal_period,round(np.sqrt(mse_dynamic), 2)))\n",
        "\n",
        "    ax = y.plot(label='observado')\n",
        "    y_forecasted_dynamic.plot(label='Predicción dinámica', ax=ax,figsize=(14, 7))\n",
        "    ax.fill_between(pred_dynamic_ci.index,\n",
        "                    pred_dynamic_ci.iloc[:, 0],\n",
        "                    pred_dynamic_ci.iloc[:, 1], color='k', alpha=.2)\n",
        "\n",
        "    ax.set_xlabel('Fecha')\n",
        "    ax.set_ylabel('Trend')\n",
        "\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    return (results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TOSH8Z2hYhJ"
      },
      "outputs": [],
      "source": [
        "model = sarima_eva(diet,(0, 1, 1),(1, 1, 1, 12),52,predict_date,diet_to_test)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}